# Streams-of-Anomalies_JK

The objective of this project was to use anomaly detection models to detect anomalies within time-sensitive data. The data used is that of Twitter statistics of company mentions over a set period of time (datasets available here: https://github.com/numenta/NAB/tree/master/data/realTweets). Since the dataset was simple and straightforward, no data cleaning was necessary. However, due to the fact that only two columns were in the original dataset, some feature engineering was necessary. The first engineered feature was the mention difference, which found the difference in tweets from the current and last rows. Another engineered feature was the weekday on which the tweet was made. The weekday was obtained from the timestamp and onehot encoded to allow for easier translation to the models that were used for anomaly detection. The models used for this project were isolation forest and local outlier factor (LOF) models with the standard hyperparameters. The anomaly detection was not very good for the isolation forest model, as there was a lot of overlap with normal data and anomalous data. This issue would have probably been solvable if an additional engineered feature representing the hour of the day were included. The LOF model identified much less anomalies in the data, but it was not able to catch all of the present anomalies, as many spikes in the data were not labelled as outliers. Overall, the models were not as accurate as they could have been with more engineered features, but the LOF model was still able to detect several obvious data anomalies without labeling too much of the "normal" data as anomalous. 
